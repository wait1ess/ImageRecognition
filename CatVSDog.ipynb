{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 猫狗大战"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成图片路径和标签的List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step1：获取.../data/Cat下所有的猫图路径名，存放到cats中，同时贴上标签0，存放到label_cats中。狗图同理。\n",
    "def get_files(file_dir):\n",
    "    cats=[]\n",
    "    label_cats=[]\n",
    "    dogs=[]\n",
    "    label_dogs=[]\n",
    "    for file in os.listdir(file_dir+'/Cat'):\n",
    "            cats.append(file_dir +'/Cat'+'/'+ file) \n",
    "            label_cats.append(0)\n",
    "    for file in os.listdir(file_dir+'/Dog'):\n",
    "            dogs.append(file_dir +'/Dog'+'/'+file)\n",
    "            label_dogs.append(1)\n",
    "            \n",
    "            \n",
    "#step2：对生成的图片路径和标签List做打乱处理\n",
    "    #把cat和dog合起来组成一个list（img和lab）\n",
    "    image_list = np.hstack((cats, dogs))                             # 路径列表\n",
    "    label_list = np.hstack((label_cats, label_dogs))                 # 标签列表，猫为0，狗为1\n",
    "\n",
    "    #利用shuffle打乱顺序\n",
    "    temp = np.array([image_list, label_list])                        # 两个列表放于数组中\n",
    "    temp = temp.transpose()                                          # 转置\n",
    "    np.random.shuffle(temp)                                          # 打乱顺序\n",
    "\n",
    "    #从打乱的temp中再取出list（img和lab）\n",
    "    image_list = list(temp[:, 0])                                    # temp第一列为图片路径\n",
    "    \n",
    "    label_list = list(temp[:, 1])                                    # 第二列为label\n",
    "    label_list = [float(i) for i in label_list]                        # label转换为int格式\n",
    "    return image_list,label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step1：将上面生成的List传入get_batch() ，转换类型，产生一个输入队列queue，因为img和lab是分开的，所以使用tf.train.slice_input_producer()，然后用tf.read_file()从队列中读取图像\n",
    "def get_batch(image, label, image_W, image_H, batch_size, capacity):\n",
    "    '''\n",
    "    image_W, image_H, ：设置好固定的图像高度和宽度\n",
    "    batch_size：每个batch要放多少张图片\n",
    "    capacity：一个队列最大多少\n",
    "    '''\n",
    "    #转换类型\n",
    "    image = tf.cast(image, tf.string)                                         # tf.cast 转换类型\n",
    "    label = tf.cast(label, tf.int32)\n",
    "\n",
    "    # make an input queue\n",
    "    input_queue = tf.train.slice_input_producer([image, label])               # tf.train.slice_input_producer()  产生一个输入队列queue input_queue\n",
    "\n",
    "    label = input_queue[1]                                                    # label不需经过转换\n",
    "    image_contents = tf.read_file(input_queue[0]) #read img from a queue      # image需经tf.read_file从队列中读取图片\n",
    "    \n",
    "    \n",
    "#step2：将图像解码，不同类型的图像不能混在一起，要么只用jpeg，要么只用png等。\n",
    "    image = tf.image.decode_jpeg(image_contents, channels=3)                 # 图片读取后，利用tf.image.decode_jpeg进行解码\n",
    "    \n",
    "    \n",
    "#step3：数据预处理，对图像进行旋转、缩放、裁剪、归一化等操作，让计算出的模型更健壮。\n",
    "    image = tf.image.resize_image_with_crop_or_pad(image, image_W, image_H)  #  tf.image.resize_image_with_crop_or_pad设置图像的宽度和高度\n",
    "    image = tf.image.per_image_standardization(image)                        #  tf.image.per_image_standardization 图片标准化\n",
    "\n",
    "#step4：生成batch\n",
    "#image_batch: 4D tensor [batch_size, width, height, 3],dtype=tf.float32\n",
    "#label_batch: 1D tensor [batch_size], dtype=tf.int32\n",
    "    image_batch, label_batch = tf.train.batch([image, label],                # tf.train.batch\n",
    "                                                batch_size= batch_size,\n",
    "                                                num_threads= 32)\n",
    "    return image_batch, label_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step1：变量初始化，每批2张图，尺寸208x208，设置好自己的图像路径\n",
    "BATCH_SIZE = 1\n",
    "CAPACITY = 256\n",
    "IMG_W = 208\n",
    "IMG_H = 208\n",
    "train_dir = 'D:/CatVSDog/train'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（这里有个问题：官网的start_queue_runners()是有两个参数的，sess和coord，但是在这里加上sess的话会报错）。 \n",
    "利用try——except——finally结构来执行队列操作（官网推荐的方法），避免程序卡死什么的。i<2:先执行两次队列操作，每一次取出2张图放进batch里面，然后imshow出来看看效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):                                                # 建立变量，初始化权值的函数  （filter的权值）\n",
    "    return tf.Variable(tf.truncated_normal(shape,stddev=0.1))\n",
    "def bias_vairable(shape):                                                 # 建立变量，初始化偏置值的函数\n",
    "    return tf.Variable(tf.constant(0.1, shape=shape))\n",
    "def conv2d(x,W):                                                          # 卷积的函数 tf.nn.conv2d    \n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME') \n",
    "def max_pool_2x2(x):                                                     # 池化的函数，这里用最大池化\n",
    "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,[None,208,208,3])                         # 208*208的图片 \n",
    "y = tf.placeholder(tf.float32,[None,2])                                 # 两分类  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)                                  # drop out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer 1\n",
    "#conv\n",
    "W_conv1 = weight_variable([5,5,3,32])                                    \n",
    "b_conv1 = bias_vairable([32])  \n",
    "h_conv1 = tf.nn.relu(conv2d(x, W_conv1) + b_conv1)\n",
    "#pooling\n",
    "h_pool1 = max_pool_2x2(h_conv1)                                    # 104x104x32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer 2\n",
    "#conv\n",
    "W_conv2 = weight_variable([5,5,32,64])                                   \n",
    "b_conv2 = bias_vairable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1,W_conv2) + b_conv2)\n",
    "#pooling                                                                 \n",
    "h_pool2 = max_pool_2x2(h_conv2)                                   # 52x52x64     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer 3\n",
    "#conv\n",
    "W_conv3 = weight_variable([5,5,64,128])                                   \n",
    "b_conv3 = bias_vairable([128])\n",
    "h_conv3 = tf.nn.relu(conv2d(h_pool2,W_conv3) + b_conv3)\n",
    "#pooling                                                                 \n",
    "h_pool3 = max_pool_2x2(h_conv3)                                   # 26x26x128    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer 4\n",
    "#conv\n",
    "W_conv4 = weight_variable([5,5,128,256])                                   \n",
    "b_conv4 = bias_vairable([256])\n",
    "h_conv4 = tf.nn.relu(conv2d(h_pool3,W_conv4) + b_conv4)\n",
    "#pooling                                                                 \n",
    "h_pool4 = max_pool_2x2(h_conv4)                                   # 13x13x256 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer 5\n",
    "#fullly connected 1\n",
    "W_fc1 = weight_variable([13*13*256,1024])                                   # 第一个全连接层，全连接层的                               \n",
    "b_fc1 = bias_vairable([1024])\n",
    "\n",
    "h_pool4_flat = tf.reshape(h_pool4,[-1,13*13*256])                            # 扁平化\n",
    "\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool4_flat, W_fc1) + b_fc1)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer 7\n",
    "#fullly connected 2\n",
    "#output layer\n",
    "W_fc2 = weight_variable([1024,2])\n",
    "b_fc2 = bias_vairable([2])\n",
    "logits = tf.matmul(h_fc1_drop,W_fc2) + b_fc2\n",
    "prediction = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = tf.train.AdamOptimizer(0.2).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(prediction,1)) # argmax 返回一维张量中最大值索引( 在axis=1的轴上找 )\n",
    "                                                                       # 求准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))      # 把布尔值转换为浮点型tf.float32  False=0,True=1 求平均数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-4ccaa6476d6a>:6: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.\n",
      "WARNING:tensorflow:From <ipython-input-3-0eabe2acc8fb>:13: slice_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(tuple(tensor_list)).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\training\\input.py:372: range_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.range(limit).shuffle(limit).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\training\\input.py:318: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\training\\input.py:188: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\training\\input.py:197: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\training\\input.py:197: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From <ipython-input-3-0eabe2acc8fb>:32: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
      "epoch0 done \n"
     ]
    }
   ],
   "source": [
    "#step3：开启会话session，利用tf.train.Coordinator()和tf.train.start_queue_runners(coord=coord)来监控队列\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    i = 0\n",
    "    coord = tf.train.Coordinator()                                         # tf.train.Coordinator()和tf.train.start_queue_runners(coord=coord)来监控队列\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "    for epoch in range(1):                                  # 迭代21个周期\n",
    "        for batch in range(1):                              # 遍历批次\n",
    "            try:                                                                   # 利用try——except——finally结构来执行队列操作\n",
    "                while not coord.should_stop() and i<1:\n",
    "# step2：调用前面的两个函数，生成batch\n",
    "                    image_list, label_list = get_files(train_dir)                                                    # get_files得到图片路径及对应的label\n",
    "                    image_batch, label_batch = get_batch(image_list, label_list, IMG_W, IMG_H, BATCH_SIZE, CAPACITY) # 输入图像路径 label路径，图宽，图长，批次大小，输出图片的tf类的4维张量，输出lebal的rank1array\n",
    "\n",
    "                                  # tf张量转换为 ndarray\n",
    "            \n",
    "                    #label=label.reshape(-1,1)                                      # rank1array转换（n,1）向量 n为batch_size\n",
    "                    #label_onehot=np.eye(2)[label.reshape(-1)].astype(int)          # 标签的onehot转换\n",
    "                    \n",
    "                    #batch_xs, batch_ys = img, label_onehot                  # 获得一个批次为batch_size的图片的像素点数据和标签\n",
    "                    #sess.run(train_step, feed_dict={x:img, y:label_onehot,  keep_prob:0.6})                  # 训练，更新变量w和b\n",
    "                    print(\"epoch\" + str(epoch) + \" done \")\n",
    "                    \n",
    "                    \n",
    "                    # 输出原图片\n",
    "                    # just test one batch\n",
    "                    #for j in np.arange(BATCH_SIZE):\n",
    "                        #print('label: %d' %label[j])                              #\n",
    "                        #plt.imshow(img[j,:,:,:])\n",
    "                        #plt.show()\n",
    "                    i+=1\n",
    "\n",
    "                    \n",
    "                    \n",
    "            except tf.errors.OutOfRangeError:\n",
    "                print('done!')\n",
    "            finally:\n",
    "                coord.request_stop()\n",
    "            coord.join(threads)\n",
    "            img, label = sess.run([image_batch, label_batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)                                          # 执行初始化\n",
    "    for epoch in range(1):                                  # 迭代21个周期\n",
    "        for batch in range(1):                              # 遍历批次\n",
    "                                                            # 获得批次数据\n",
    "            batch_xs, batch_ys = img, label_onehot                  # 获得一个批次为batch_size的图片的像素点数据和标签\n",
    "            sess.run(train_step, feed_dict={x:img, y:label_onehot,  keep_prob:0.6})                  # 训练，更新变量w和b\n",
    "        #acc = sess.run(accuracy, feed_dict={x:mnist.test.images,y:mnist.test.labels}) # 观察准确率的变化\n",
    "        #print(\"Iter \" + str(epoch) + \" Testing Accuracy: \" + str(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
